# -*- coding: utf-8 -*-
"""fire_detection_sklearn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DcYlB6nHpYFWGFw1SvsCJeLLXB9Qqv2Y
"""

import zipfile
import os
import cv2
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score
import pickle

"""Function to extract the zip file"""

def extract_zip(zip_path, extract_to):
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_to)
    print(f"Extracted zip file to {extract_to}")

"""Function to load images from extracted folder and assign labels based on subfolder names

"""

def load_images_from_folder(main_folder, img_size=(32, 32)):
    images = []
    labels = []
    classes = os.listdir(main_folder)  # Should contain folders named '1' and '0'

    for class_name in classes:
        class_folder = os.path.join(main_folder, class_name)
        if os.path.isdir(class_folder):  # Ensure it's a folder
            for filename in os.listdir(class_folder):
                img_path = os.path.join(class_folder, filename)
                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Read image in grayscale
                if img is not None:
                    img_resized = cv2.resize(img, img_size)  # Resize image to the specified size
                    img_flattened = img_resized.flatten()    # Flatten image to 1D array
                    images.append(img_flattened)
                    labels.append(int(class_name))  # Convert folder name '1' or '0' to integer label

    return np.array(images), np.array(labels)  # Return images and labels as NumPy arrays

"""Path to the zip file"""

zip_path = 'archive.zip'
extract_to = 'dataset'  # Path to extract the zip contents

"""Extract the zip file"""

extract_zip(zip_path, extract_to)

"""Path to the extracted folder"""

extracted_folder_path = os.path.join(extract_to, 'myData')

"""training data"""

X, y = load_images_from_folder(extracted_folder_path)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

print(f"Training data shape: {X_train.shape}, Testing data shape: {X_test.shape}")

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

model = MLPClassifier(hidden_layer_sizes=(64, 64), max_iter=250, verbose=True)
model.fit(X_train, y_train)

"""predictions"""

y_train_pred = model.predict(X_train)
y_test_pred = model.predict(X_test)

"""Evaluate accuracy"""

print('Training accuracy:', accuracy_score(y_train, y_train_pred) * 100, '%')
print('Testing accuracy:', accuracy_score(y_test, y_test_pred) * 100, '%')

"""Example prediction"""

print('Prediction for one sample:', model.predict([X_test[55]]), y_test[55])

"""save"""

model_filename = 'trained_model.pkl'
with open(model_filename, 'wb') as file:
    pickle.dump(model, file)  # Save the model
print(f"Model saved as {model_filename}")

"""load model"""

with open(model_filename, 'rb') as file:
    loaded_model = pickle.load(file)

"""Make predictions with the loaded model"""

y_test_pred_loaded_model = loaded_model.predict(X_test)

# Evaluate the accuracy of the loaded model
print('Testing accuracy with loaded model:', accuracy_score(y_test, y_test_pred_loaded_model) * 100, '%')